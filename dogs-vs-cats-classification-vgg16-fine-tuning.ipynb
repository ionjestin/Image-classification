{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{"_uuid":"fe76d1d1ded592430e7548feacfa38dc42f085d9"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\n\nimport os\nprint(os.listdir(\"../input\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-04T16:02:37.513574Z","iopub.execute_input":"2023-07-04T16:02:37.513816Z","iopub.status.idle":"2023-07-04T16:02:38.314994Z","shell.execute_reply.started":"2023-07-04T16:02:37.513766Z","shell.execute_reply":"2023-07-04T16:02:38.313935Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"},{"name":"stdout","text":"['test1.zip', 'train.zip', 'sampleSubmission.csv']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare Traning Data","metadata":{"_uuid":"7335a579cc0268fba5d34d6f7558f33c187eedb3"}},{"cell_type":"code","source":"filenames = os.listdir(\"/kaggle/input/dogs-vs-cats/test1.zip\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-07-04T16:09:40.687164Z","iopub.execute_input":"2023-07-04T16:09:40.687487Z","iopub.status.idle":"2023-07-04T16:09:40.708296Z","shell.execute_reply.started":"2023-07-04T16:09:40.687434Z","shell.execute_reply":"2023-07-04T16:09:40.707005Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f00e6abda176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/dogs-vs-cats/test1.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/dogs-vs-cats/test1.zip'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/dogs-vs-cats/test1.zip'","output_type":"error"}]},{"cell_type":"markdown","source":"### See Total In count","metadata":{"_uuid":"a999484fc35b73373fafe2253ae9db7ff46fdb90"}},{"cell_type":"code","source":"df['category'].value_counts().plot.bar()","metadata":{"_uuid":"fa26f0bc7a6d835a24989790b20f3c6f32946f45","execution":{"iopub.status.busy":"2023-07-04T16:09:49.358433Z","iopub.execute_input":"2023-07-04T16:09:49.358744Z","iopub.status.idle":"2023-07-04T16:09:49.540116Z","shell.execute_reply.started":"2023-07-04T16:09:49.358688Z","shell.execute_reply":"2023-07-04T16:09:49.539130Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7c5645438400>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# See sample image","metadata":{"_uuid":"400a293df3c8499059d9175f3915187074efd971"}},{"cell_type":"code","source":"sample = random.choice(filenames)\nimage = load_img(\"../input/train/train/\"+sample)\nplt.imshow(image)","metadata":{"_uuid":"602b40f7353871cb161c60b5237f0da0096b2f47","execution":{"iopub.status.busy":"2023-07-04T16:09:56.393566Z","iopub.execute_input":"2023-07-04T16:09:56.393869Z","iopub.status.idle":"2023-07-04T16:09:56.424961Z","shell.execute_reply.started":"2023-07-04T16:09:56.393813Z","shell.execute_reply":"2023-07-04T16:09:56.423530Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8b1dcb7680f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/train/train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train/train/train.zip'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/train/train/train.zip'","output_type":"error"}]},{"cell_type":"markdown","source":"# Build Model","metadata":{"_uuid":"b244e6b7715a04fc6df92dd6dfa3d35c473ca600"}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.applications import VGG16\nfrom keras.models import Model\n\nimage_size = 224\ninput_shape = (image_size, image_size, 3)\n\nepochs = 5\nbatch_size = 16\n\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    \nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n    \n# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"_uuid":"8c9f833c1441b657c779844912d0b8028218d454","execution":{"iopub.status.busy":"2023-07-04T16:02:38.811581Z","iopub.status.idle":"2023-07-04T16:02:38.814067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Test and Train Data","metadata":{"_uuid":"a29ebfd697dd7183a1a1345ea41ec138874340b7"}},{"cell_type":"code","source":"train_df, validate_df = train_test_split(df, test_size=0.1)\ntrain_df = train_df.reset_index()\nvalidate_df = validate_df.reset_index()\n\n# validate_df = validate_df.sample(n=100).reset_index() # use for fast testing code purpose\n# train_df = train_df.sample(n=1800).reset_index() # use for fast testing code purpose\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]","metadata":{"_uuid":"4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef","execution":{"iopub.status.busy":"2023-07-04T16:02:38.814933Z","iopub.status.idle":"2023-07-04T16:02:38.819145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traning Generator","metadata":{"_uuid":"ff760be9104f7d9492467b8d9d3405011aa77d11"}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"../input/train/train/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","metadata":{"_uuid":"4d1c7818703a8a4bac5c036fdea45972aa9e5e9e","execution":{"iopub.status.busy":"2023-07-04T16:02:38.820253Z","iopub.status.idle":"2023-07-04T16:02:38.820968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Generator","metadata":{"_uuid":"859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"}},{"cell_type":"code","source":"validation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"../input/train/train/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary',\n    target_size=(image_size, image_size),\n    batch_size=batch_size\n)","metadata":{"_uuid":"7925e16bcacc89f4484fb6fe47e54d6420af732e","execution":{"iopub.status.busy":"2023-07-04T16:02:38.821852Z","iopub.status.idle":"2023-07-04T16:02:38.822552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# See sample generated images","metadata":{"_uuid":"6e17fc1f002fedd60febb78fee5e81770640b909"}},{"cell_type":"code","source":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"../input/train/train/\", \n    x_col='filename',\n    y_col='category',\n    class_mode='binary'\n)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"23d923dba747f8b47dc75569244cecc6f70df321","execution":{"iopub.status.busy":"2023-07-04T16:02:38.823413Z","iopub.status.idle":"2023-07-04T16:02:38.830456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit Model","metadata":{"_uuid":"5cd8df64e794ed17de326b613a9819e7da977a0e"}},{"cell_type":"code","source":"# fine-tune the model\nhistory = model.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size)","metadata":{"_uuid":"0836a4cc8aa0abf603e0f96573c0c4ff383ad56b","execution":{"iopub.status.busy":"2023-07-04T16:02:38.831347Z","iopub.status.idle":"2023-07-04T16:02:38.832035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"a624dbb9f5195e47f79c8f2a73d63d337b3cffa2"}},{"cell_type":"code","source":"loss, accuracy = model.evaluate_generator(validation_generator, total_validate//batch_size, workers=12)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","metadata":{"_uuid":"e196e7807ffd55aa404481acdf2fc96e01c238aa","execution":{"iopub.status.busy":"2023-07-04T16:02:38.832894Z","iopub.status.idle":"2023-07-04T16:02:38.833597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_model_history(model_history, acc='acc', val_acc='val_acc'):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplot_model_history(history)","metadata":{"_uuid":"37e05b06e4131600f27d663f2098a2310750f13c","execution":{"iopub.status.busy":"2023-07-04T16:02:38.834524Z","iopub.status.idle":"2023-07-04T16:02:38.835222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_val = validate_df['category']\ny_pred =  model.predict_generator(validation_generator)","metadata":{"_uuid":"800b2cbabf53dd1725edfa1d82bcf31f05217222","execution":{"iopub.status.busy":"2023-07-04T16:02:38.836048Z","iopub.status.idle":"2023-07-04T16:02:38.836744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.5\ny_final = np.where(y_pred > threshold, 1,0)","metadata":{"_uuid":"834bd766b3fa473bf85328d10625a38adbfb5cd9","execution":{"iopub.status.busy":"2023-07-04T16:02:38.837594Z","iopub.status.idle":"2023-07-04T16:02:38.838275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_final.size","metadata":{"_uuid":"7c427f212c00d161924fa5747c8dc23b19e9787a","execution":{"iopub.status.busy":"2023-07-04T16:02:38.845636Z","iopub.status.idle":"2023-07-04T16:02:38.846334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n# Predict the values from the validation dataset\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_val, y_final) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"_uuid":"875a42b6dee96997a8cbc4f4d7839aabd047cae0","execution":{"iopub.status.busy":"2023-07-04T16:02:38.847260Z","iopub.status.idle":"2023-07-04T16:02:38.848071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(Y_val, y_final, target_names=['0','1'])\n\nprint(report)","metadata":{"_uuid":"20e4ce1c5271a7f36364a69972ba3c3f1219ee6a","execution":{"iopub.status.busy":"2023-07-04T16:02:38.849006Z","iopub.status.idle":"2023-07-04T16:02:38.849703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Testing Data","metadata":{"_uuid":"764dc66e4b2bc558f3a0f90b80bb802f5b3d45a8"}},{"cell_type":"code","source":"test_filenames = os.listdir(\"../input/test1/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","metadata":{"_uuid":"c35e70d3e1e4834dbbf840fa0ea08c049bfcd915","execution":{"iopub.status.busy":"2023-07-04T16:02:38.850548Z","iopub.status.idle":"2023-07-04T16:02:38.851268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Testing Generator","metadata":{"_uuid":"291bc3996dce8d05e174b27d64f03996d3e8038e"}},{"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"../input/test1/test1/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    batch_size=batch_size,\n    target_size=(image_size, image_size),\n    shuffle=False\n)","metadata":{"_uuid":"52249ec1c35fb1be3adef386be245de3794e55aa","execution":{"iopub.status.busy":"2023-07-04T16:02:38.852104Z","iopub.status.idle":"2023-07-04T16:02:38.852801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{"_uuid":"2fa580afca2931ec5ce374e732d8c1789d03f2ed"}},{"cell_type":"code","source":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\nthreshold = 0.5\ntest_df['category'] = np.where(predict > threshold, 1,0)","metadata":{"_uuid":"4782eb23fa7d003f0e2415d995894017edb2d896","execution":{"iopub.status.busy":"2023-07-04T16:02:38.853645Z","iopub.status.idle":"2023-07-04T16:02:38.860454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# See predicted result","metadata":{"_uuid":"ce72a83f80d6e012b12b82c8ee3365d671a3b307"}},{"cell_type":"code","source":"sample_test = test_df.sample(n=9).reset_index()\nsample_test.head()\nplt.figure(figsize=(12, 12))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"../input/test1/test1/\"+filename, target_size=(256, 256))\n    plt.subplot(3, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"98b41dc83075e6297137fb45bf703c313dd4ae28","execution":{"iopub.status.busy":"2023-07-04T16:02:38.861333Z","iopub.status.idle":"2023-07-04T16:02:38.862016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"_uuid":"d1ca25943e73aa20a37f9fb8670ee430caeaaf1f"}},{"cell_type":"code","source":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission_13010030.csv', index=False)\n\nplt.figure(figsize=(10,5))\nsns.countplot(submission_df['label'])\nplt.title(\"(Test data)\")","metadata":{"_uuid":"cce9f3e2ffff0693d79d84590ed71fbbca7c3c7c","execution":{"iopub.status.busy":"2023-07-04T16:02:38.862903Z","iopub.status.idle":"2023-07-04T16:02:38.863608Z"},"trusted":true},"execution_count":null,"outputs":[]}]}